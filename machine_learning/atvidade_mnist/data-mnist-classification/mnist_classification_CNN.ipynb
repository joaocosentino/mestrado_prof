{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Number recognition](recognition.gif)\n",
    "\n",
    "*Note: The animation above is just here to help you visualize what happens with the different images: <br/> $\\rightarrow$ For each image, once the CNN is trained, it will predict what digit is written. The inputs are the different digits and not one animation/video!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets, metrics\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  `MNIST` Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(((60000, 28, 28), (60000,)), ((10000, 28, 28), (10000,)))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importantdo o MNIST Dataset...\n",
    "(X_train, y_train), (X_test, y_test) = datasets.mnist.load_data(path=\"mnist.npz\")\n",
    "\n",
    "# The train set contains 60 000 images, each of them of size 28x28\n",
    "# The test set contains 10 000 images, each of them of size 28x28\n",
    "(X_train.shape, y_train.shape), (X_test.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1.1) Exploring the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f8394407fd0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_train[2,:,:],cmap='gray')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1.2) Image Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùóÔ∏è **Neural Networks convergem mais r√°pido quando os dados est√£o normalizados** ‚ùóÔ∏è\n",
    "\n",
    "üë©üèª‚Äçüè´ Para as Convolutional Neural Networks ?\n",
    "* Os canais `RBG` possuem as intensidades decodificadas entre 0 e 255. \n",
    "* Para tanto vamos dividir os dois datasets por 255, ent√£o teremos os valores dentre 0 e 1üòâ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "X_train = X_train/255\n",
    "X_test = X_test/255\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1.3) Inputs' Shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**√â preciso expandir o formato dos dados a serem inseridos na rede, pois as CNNs exigem que a quantidade de canais de cada pixel seja dita**\n",
    "\n",
    "No nosso caso, como a imagem est√° em gray scale ent√£o s√≥ possui um canal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-02 13:47:25.373702: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-02 13:47:25.374008: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-12-02 13:47:25.374089: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2023-12-02 13:47:25.374149: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2023-12-02 13:47:25.374240: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2023-12-02 13:47:25.374339: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2023-12-02 13:47:25.374449: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2023-12-02 13:47:25.374494: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2023-12-02 13:47:25.374534: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2023-12-02 13:47:25.374542: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-12-02 13:47:25.379278: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.backend import expand_dims\n",
    "X_train = expand_dims(X_train,axis=-1)\n",
    "X_test = expand_dims(X_test,axis=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1) (10000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape,X_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1.4) Target encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "y_train_cat = to_categorical(y_train,num_classes=10)\n",
    "y_test_cat = to_categorical(y_test,num_classes=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick check that you correctly used to_categorical\n",
    "assert(y_train_cat.shape == (60000,10))\n",
    "assert(y_test_cat.shape == (10000,10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is now ready to be used. ‚úÖ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (2) Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2.1) Definindo uma Arquitetura e par√¢metros de compila√ß√£o da CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "\n",
    "\n",
    "def initialize_model():\n",
    "\n",
    "    model = models.Sequential()\n",
    "\n",
    "    ### First Convolution & MaxPooling\n",
    "    model.add(layers.Conv2D(16,(4,4),input_shape=(28,28,1),activation='relu',padding='same'))\n",
    "    model.add(layers.MaxPool2D(pool_size=(2,2)))\n",
    "\n",
    "    ### Second Convolution & MaxPooling\n",
    "    model.add(layers.Conv2D(32,(3,3),activation='relu',padding='same'))\n",
    "    model.add(layers.MaxPool2D(pool_size=(2,2)))\n",
    "    ### Flattening\n",
    "    model.add(layers.Flatten())\n",
    "    ### One Fully Connected layer - \"Fully Connected\" is equivalent to saying \"Dense\"\n",
    "    model.add(layers.Dense(30,activation='relu'))\n",
    "    model.add(layers.Dropout(0.2))\n",
    "    ### Last layer - Classification Layer with 10 outputs corresponding to 10 digits\n",
    "    model.add(layers.Dense(10,activation='softmax'))\n",
    "    ### Model compilation\n",
    "    model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An√°lis da quantidade de par√¢metros gerados pela rede"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_12 (Conv2D)          (None, 28, 28, 16)        272       \n",
      "                                                                 \n",
      " max_pooling2d_12 (MaxPoolin  (None, 14, 14, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_13 (Conv2D)          (None, 14, 14, 32)        4640      \n",
      "                                                                 \n",
      " max_pooling2d_13 (MaxPoolin  (None, 7, 7, 32)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_6 (Flatten)         (None, 1568)              0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 30)                47070     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 30)                0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 10)                310       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 52,292\n",
      "Trainable params: 52,292\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = initialize_model()\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2.2) Treinameneto da CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.2728 - accuracy: 0.9141\n",
      "Epoch 2/2\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.1033 - accuracy: 0.9680\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f831c446500>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "model.fit(X_train,y_train_cat,\n",
    "          validation_split = 0.3,\n",
    "          epochs=2,batch_size=32,verbose=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Com `verbose = 1` ao treinar o model temos acesso ao numero de itera√ßoes para cada epoch.\n",
    "    \n",
    "N√∫mero de imagens = 60000\n",
    "batch_size = 32\n",
    "\n",
    "* Para cada epoch, temos $ \\large \\lceil \\frac{60000}{32} \\rceil = 1875$ minibatches <br/>\n",
    "* O _validation_split_ √© $0.3$ - o que significa que para cada epoch:\n",
    "    * $ \\lceil 1875 \\times (1 - 0.3) \\rceil = \\lceil 1312.5 \\rceil = 1313$ batches s√£o usados para computar `train_loss` \n",
    "    * $ 1875 - 1312 = 562 $ consequentemente 562 s√£o para calcular `val_loss`\n",
    "    * **Os parametros s√£o atualiazdos 1313 vezes por epoch** pois s√£o 1313 forward/backward propagations por epoch !!!\n",
    "\n",
    "\n",
    "\n",
    "</details>    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2.3) Avaliando a Performance da Rede Convolucional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Descobrindo a **`accuracy no  test set`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.046758733689785004, 0.9861000180244446]\n",
      "313/313 [==============================] - 1s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "print(model.evaluate(X_test, y_test_cat, verbose=0))\n",
    "predicted = model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`Ajustando o shape das respostas com o resultado predito pela CNN`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels = np.argmax(predicted, axis=1)\n",
    "true_labels = np.argmax(y_test_cat,axis=1)\n",
    "assert(true_labels.shape == predicted_labels.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 974    0    2    0    0    0    1    1    2    0]\n",
      " [   0 1123    3    2    0    0    3    0    4    0]\n",
      " [   2    1 1024    2    0    0    0    1    2    0]\n",
      " [   0    0    0 1001    0    3    0    3    3    0]\n",
      " [   0    0    1    0  974    0    2    0    1    4]\n",
      " [   1    0    0    6    0  877    3    2    3    0]\n",
      " [   2    3    0    0    2    3  944    0    4    0]\n",
      " [   0    3   10    4    0    0    0 1005    2    4]\n",
      " [   4    0    2    1    2    0    0    3  959    3]\n",
      " [   2    4    1    1    6    4    0    6    5  980]]\n"
     ]
    }
   ],
   "source": [
    "matriz_confusao = confusion_matrix(true_labels, predicted_labels)\n",
    "print(matriz_confusao)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for classifier <keras.engine.sequential.Sequential object at 0x7f83781276d0>:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       980\n",
      "           1       0.99      0.99      0.99      1135\n",
      "           2       0.98      0.99      0.99      1032\n",
      "           3       0.98      0.99      0.99      1010\n",
      "           4       0.99      0.99      0.99       982\n",
      "           5       0.99      0.98      0.99       892\n",
      "           6       0.99      0.99      0.99       958\n",
      "           7       0.98      0.98      0.98      1028\n",
      "           8       0.97      0.98      0.98       974\n",
      "           9       0.99      0.97      0.98      1009\n",
      "\n",
      "    accuracy                           0.99     10000\n",
      "   macro avg       0.99      0.99      0.99     10000\n",
      "weighted avg       0.99      0.99      0.99     10000\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    f\"Classification report for classifier {model}:\\n\"\n",
    "    f\"{metrics.classification_report(true_labels, predicted_labels)}\\n\"\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "e588d92b224e11b16adbbadd39936dea13a6488171770263a646fc57f44563d8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
